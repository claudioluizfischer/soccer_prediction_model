# -*- coding: utf-8 -*-
"""Soccer_pred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CQaCRnrySZqo7PZjt1VUdGZG83HggDi1
"""

#Webscrapting info for df
#Predicting the winning Soccer Team
# Designed a predictive model capable of accurately predicting if the home team will win a soccer match
#Multi Classification
#ML ->Random Forest Classifier
#Use rolling averages to try to increase the accuracy

import requests

"""#Web scraping"""

standings_url = "https://fbref.com/en/comps/9/11160/2021-2022-Premier-League-Stats"

data = requests.get(standings_url)

data.text

from bs4 import BeautifulSoup

soup = BeautifulSoup(data.text)

standings_table = soup.select("table.stats_table")[0]

standings_table

#get the a tags and then the hrefs with the links
links = standings_table.find_all('a')

links = [l.get('href') for l in links]

links = [l for l in links if '/squads/' in l]

links

#add a domain to that => format string
team_urls = [f'http://fbref.com{l}' for l in links]

team_urls

team_url = team_urls[0]

team_url

data = requests.get(team_url)

data.text

#the data that we want to use for each team
import pandas as pd

matches = pd.read_html(data.text, match = 'Scores & Fixtures')

matches[0]

#Get more info for shooting, penalties etc
soup = BeautifulSoup(data.text)

links = soup.find_all('a')

#list comprehension
links = [l.get('href') for l in links]

links = [l for l in links if l and 'all_comps/shooting/' in l]

links

data = requests.get(f'https://fbref.com{links[0]}')

data.text

shooting_stats = pd.read_html(data.text, match = "Shooting")[0]

shooting_stats

#Drop one index level
shooting_stats.columns = shooting_stats.columns.droplevel()

shooting_stats.head()

#merge both df
matches = matches[0]
team_data = matches.merge(shooting_stats[['Date', 'Sh', 'SoT', 'Dist', 'FK', 'PK', 'PKatt']], on = 'Date')

team_data.head()

#Get data from multiple seasons and teams
years = list(range(2022, 2020, -1))

years

all_matches = []

standings_url = "https://fbref.com/en/comps/9/11160/2021-2022-Premier-League-Stats"

from sqlalchemy.inspection import exc
from requests.api import request

import time

for year in years:
  data = requests.get(standings_url)
  soup = BeautifulSoup(data.text)
  standings_table = soup.select("table.stats_table")[0]

  links = [l.get('href') for l in standings_table.find_all('a')]
  links =[l for l in links if '/squads/' in l]
  team_urls = [f'http://fbref.com{l}' for l in links]

  previous_season =soup.select('a.prev')[0].get('href')
  standings_url = f'http://fbref.com{previous_season}'

  for team_url in team_urls:
    team_name = team_url.split('/')[-1].replace('-Stats', '').replace('-', ' ')
    data = requests.get(team_url)
    matches = pd.read_html(data.text, match = 'Scores & Fixtures')[0]
    soup = BeautifulSoup(data.text)
    links = [l.get("href") for l in soup.find_all("a")]
    links =[l for l in links if l and 'all_comps/shooting/' in l]
    data = requests.get(f"https://fbref.com{links[0]}")
    shooting = pd.read_html(data.text, match = "Shooting")[0]
    shooting.columns = shooting.columns.droplevel()

    try:
      team_data = matches.merge(shooting[['Date', 'Sh', 'SoT', 'Dist', 'FK', 'PK', 'PKatt']], on = 'Date')
    except ValueError:
      continue

    team_data = team_data[team_data['Comp'] == "Premier League"]
    team_data['Season'] = year
    team_data['Team'] = team_name
    all_matches.append(team_data)
    time.sleep(3)

match_df = pd.concat(all_matches)

match_df.columns = [c.lower() for c in match_df.columns]
match_df.to_csv('matches.csv')

match_df.shape

match_df['team'].value_counts()

"""#Cleaning"""

match_df.dtypes

match_df['date'] = pd.to_datetime(match_df['date'])

match_df.dtypes

match_df.columns

"""#Machine Learning"""

import pandas as pd
match_df = pd.read_csv("matches.csv")

#Categorical to numerical values
match_df['venue_code'] = match_df['venue'].astype('category').cat.codes

match_df['opp_code'] = match_df['opponent'].astype('category').cat.codes

match_df['hour'] = match_df['time'].replace(':.+', '', regex=True).astype('int')

import pandas as pd

# Assuming 'date' column is in string format, convert it to datetime
match_df['date'] = pd.to_datetime(match_df['date'])

# Now, you can use the .dt accessor to extract the day of the week
match_df['day_code'] = match_df['date'].dt.dayofweek

match_df.head()

#train the algorithm
#Determine the variable we wnat to predict
match_df['target'] = (match_df['result']== 'W').astype('int')

#Random Classifier because our data does not have a linearity pattern
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state = 1)

#Split the train and test data
import numpy as np
train, test = np.split(match_df.sample(frac = 1), [int(0.75 * len(match_df))])

predictors = ['venue_code', 'opp_code', 'hour', 'day_code']

rf.fit(train[predictors], train['target'])

print("Number of data points in train set:", len(train))
print("Number of data points in test set:", len(test))

preds = rf.predict(test[predictors])

from sklearn.metrics import accuracy_score

accuracy_score(test['target'], preds)

combined =pd.DataFrame(dict(actual = test['target'], prediction = preds))

pd.crosstab(index=combined['actual'], columns=combined['prediction'])

171/(171+79)

from sklearn.metrics import precision_score

precision_score(test['target'], preds)

#increase accuracy by rolling accuracy
grouped_matches = match_df.groupby('team')

group = grouped_matches.get_group('Manchester City').sort_values('date')

group.head()

def rolling_averages(group, cols, new_cols):
  group = group.sort_values('date')
  rolling_stats = group[cols].rolling(3,closed='left').mean()
  group[new_cols] = rolling_stats
  group = group.dropna(subset=new_cols)
  return group

cols = ['gf', 'ga', 'sh', 'sot', 'dist', 'fk', 'pk', 'pkatt']
new_cols = [f'{c}_rolling' for c in cols]

new_cols

rolling_averages(group, cols, new_cols)

matches_rolling = match_df.groupby('team').apply(lambda x: rolling_averages(x, cols, new_cols))

matches_rolling

matches_rolling = matches_rolling.droplevel('team')

#create an index with unique values
matches_rolling.index = range(matches_rolling.shape[0])

matches_rolling

"""#Results"""

def make_prediction(data, predictiors):
  train, test = np.split(match_df.sample(frac = 1), [int(0.75 * len(match_df))])
  rf.fit(train[predictors], train['target'])
  preds = rf.predict(test[predictors])
  combined = pd.DataFrame(dict(actutal = test['target'], predicted=preds), index = test.index)
  precision = precision_score(test['target'], preds)
  return combined, precision

combined, precision = make_prediction(matches_rolling, predictors + new_cols)

precision

combined = combined.merge(matches_rolling[['date', 'team', 'opponent', 'result']], left_index=True, right_index=True)

combined

from ast import keyword
class MissingDict(dict):
  __missing__ = lambda self, key:key

map_values ={
    "Brighton and Hove Albion": "Brighton",
    "Manchester United": "Manchester Utd",
    "Newcastle United": "Newcastle Utd",
    'Tottenham hotspur': 'Tottenham',
    'West Ham United': 'West Ham',
    'Wolverhampton Wanderers': 'Wolves'
}

mapping = MissingDict(**map_values)

combined['new_team'] = combined['team'].map(mapping)

merged =combined.merge(combined, left_on=['date', 'new_team'], right_on=['date', 'opponent'])

merged.head(50)

merged[(merged['predicted_x'])== 1 & (merged['predicted_y'] == 0)]['actutal_x'].value_counts()

22/(22+13)